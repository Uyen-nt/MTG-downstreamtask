# scripts/07_evaluate.py
import os
import pickle
import numpy as np
from pathlib import Path
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# =========================================================
# ğŸ“‚ Cáº¤U HÃŒNH ÄÆ¯á»œNG DáºªN
# =========================================================
DATA_DIR = Path("/kaggle/input/downstream-data/mtg_downstream_data")
HYBRID_DIR = Path("/kaggle/working/hybrid_results")
MODEL_PATH = DATA_DIR / "pretrain_model.npz"
TREE_PATH = DATA_DIR / "tree_synth.types"

# =========================================================
# ğŸ§© LOAD Dá»® LIá»†U
# =========================================================
print("ğŸ”¹ Loading hybrid data...")
seqs = pickle.load(open(HYBRID_DIR / "merged.seqs", "rb"))
labels = pickle.load(open(HYBRID_DIR / "merged.labels", "rb"))
print(f"ğŸ“Š Tá»•ng sá»‘ bá»‡nh nhÃ¢n: {len(seqs)}")

# =========================================================
# ğŸ§± LOAD MÃ” HÃŒNH GRAM (embedding + weights)
# =========================================================
print("ğŸ”¹ Loading fine-tuned model weights...")
model_data = np.load(MODEL_PATH, allow_pickle=True)
print(f"âœ… Keys trong model: {list(model_data.keys())}")

# DÃ¹ng embedding W_emb Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ nhanh
if "W_emb" in model_data:
    embedding = model_data["W_emb"]
elif "w" in model_data and "w_tilde" in model_data:
    embedding = (model_data["w"] + model_data["w_tilde"]) / 2.0
else:
    raise KeyError("âŒ KhÃ´ng tÃ¬m tháº¥y embedding trong pretrain_model.npz")

print(f"Embedding shape: {embedding.shape}")

# =========================================================
# ğŸ§  HÃ€M Dá»° ÄOÃN ÄÆ N GIáº¢N
# =========================================================
def predict_next_visit(seq):
    if len(seq) == 0:
        return np.zeros(embedding.shape[0])
    last_visit = [idx for idx in seq[-1] if idx < embedding.shape[0]]
    if len(last_visit) == 0:
        # náº¿u táº¥t cáº£ mÃ£ vÆ°á»£t vocab, dÃ¹ng random hoáº·c trung bÃ¬nh embedding
        visit_vec = embedding.mean(axis=0)
    else:
        visit_vec = embedding[last_visit].mean(axis=0)
    sim = embedding @ visit_vec
    return np.argmax(sim)


# =========================================================
# âš™ï¸ CHáº Y Dá»° ÄOÃN VÃ€ ÄÃNH GIÃ
# =========================================================

print("ğŸš€ Predicting next diagnosis codes ...")

y_true, y_pred = [], []

for i, (seq, label) in enumerate(zip(seqs, labels)):
    if len(seq) < 1:
        continue
    pred_idx = predict_next_visit(seq)
    
    # ğŸ§  label cÃ³ thá»ƒ chá»©a nhiá»u mÃ£ bá»‡nh
    if isinstance(label[0], list):
        true_vec = np.zeros(embedding.shape[0])
        for l in label[0]:
            if l < embedding.shape[0]:
                true_vec[l] = 1
    else:
        true_vec = np.zeros(embedding.shape[0])
        if label[0] < embedding.shape[0]:
            true_vec[label[0]] = 1

    pred_vec = np.zeros(embedding.shape[0])
    pred_vec[pred_idx] = 1

    y_true.append(true_vec)
    y_pred.append(pred_vec)

y_true = np.array(y_true)
y_pred = np.array(y_pred)

# âš™ï¸ Multi-label metrics
acc = (y_true == y_pred).mean()
prec = precision_score(y_true, y_pred, average="micro", zero_division=0)
rec = recall_score(y_true, y_pred, average="micro", zero_division=0)
f1 = f1_score(y_true, y_pred, average="micro", zero_division=0)

# =========================================================
# ğŸ“ˆ IN Káº¾T QUáº¢
# =========================================================
print("\nğŸ¯ Evaluation Results (multi-label setting):")
print(f"Accuracy:  {acc:.4f}")
print(f"Precision: {prec:.4f}")
print(f"Recall:    {rec:.4f}")
print(f"F1-score:  {f1:.4f}")

print("\nâœ… ÄÃ¡nh giÃ¡ hoÃ n táº¥t! Model GRAM (fine-tuned) Ä‘Ã£ Ä‘Æ°á»£c kiá»ƒm tra trÃªn dá»¯ liá»‡u hybrid.")

