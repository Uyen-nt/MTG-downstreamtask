# =========================================================
# ğŸ“‚ Cáº¤U HÃŒNH ÄÆ¯á»œNG DáºªN
# =========================================================
import os
import pickle
import numpy as np
from pathlib import Path
from sklearn.metrics import precision_score, recall_score, f1_score

DATA_DIR = Path("/kaggle/input/downstream-data/mtg_downstream_data")
HYBRID_DIR = Path("/kaggle/working/hybrid_results")
MODEL_PATH = DATA_DIR / "pretrain_model.npz"
TREE_PATH = DATA_DIR / "tree_synth.types"

# =========================================================
# ğŸ§© LOAD Dá»® LIá»†U
# =========================================================
print("ğŸ”¹ Loading hybrid data...")
seqs = pickle.load(open(HYBRID_DIR / "merged.seqs", "rb"))
labels = pickle.load(open(HYBRID_DIR / "merged.labels", "rb"))
print(f"ğŸ“Š Tá»•ng sá»‘ bá»‡nh nhÃ¢n: {len(seqs)}")

# =========================================================
# ğŸ§± LOAD MÃ” HÃŒNH GRAM (embedding + weights)
# =========================================================
print("ğŸ”¹ Loading fine-tuned model weights...")
model_data = np.load(MODEL_PATH, allow_pickle=True)
print(f"âœ… Keys trong model: {list(model_data.keys())}")

# DÃ¹ng embedding W_emb Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ nhanh
if "W_emb" in model_data:
    embedding = model_data["W_emb"]
elif "w" in model_data and "w_tilde" in model_data:
    embedding = (model_data["w"] + model_data["w_tilde"]) / 2.0
else:
    raise KeyError("âŒ KhÃ´ng tÃ¬m tháº¥y embedding trong pretrain_model.npz")

print(f"Embedding shape: {embedding.shape}")

# =========================================================
# ğŸ§  HÃ€M Dá»° ÄOÃN
# =========================================================
def predict_next_visit(seq):
    if len(seq) == 0:
        return np.zeros(embedding.shape[0])
    last_visit = [idx for idx in seq[-1] if idx < embedding.shape[0]]
    if len(last_visit) == 0:
        visit_vec = embedding.mean(axis=0)
    else:
        visit_vec = embedding[last_visit].mean(axis=0)
    sim = embedding @ visit_vec
    return np.argmax(sim)

def predict_topk(seq, k=5):
    if len(seq) == 0:
        return []
    last_visit = [idx for idx in seq[-1] if idx < embedding.shape[0]]
    if len(last_visit) == 0:
        visit_vec = embedding.mean(axis=0)
    else:
        visit_vec = embedding[last_visit].mean(axis=0)
    sim = embedding @ visit_vec
    return np.argsort(sim)[-k:]

# =========================================================
# âš™ï¸ TÃNH TOP-5 ACCURACY
# =========================================================
topk_hits = 0
for seq, label in zip(seqs, labels):
    if len(seq) < 1:
        continue
    topk_pred = predict_topk(seq, k=5)
    true_labels = [l for l in label[0] if l < embedding.shape[0]]
    if any(l in topk_pred for l in true_labels):
        topk_hits += 1
topk_acc = topk_hits / len(seqs)
print(f"Top-5 Accuracy: {topk_acc:.4f}")

# =========================================================
# âš™ï¸ CHáº Y Dá»° ÄOÃN VÃ€ ÄÃNH GIÃ
# =========================================================
print("ğŸš€ Predicting next diagnosis codes ...")

y_true, y_pred = [], []

for i, (seq, label) in enumerate(zip(seqs, labels)):
    if len(seq) < 1:
        continue
    pred_idx = predict_next_visit(seq)

    # ğŸ§  Táº¡o vector true label
    true_vec = np.zeros(embedding.shape[0])
    for l in label[0]:
        if l < embedding.shape[0]:
            true_vec[l] = 1

    # ğŸ§  Táº¡o vector dá»± Ä‘oÃ¡n (1 nhÃ£n duy nháº¥t)
    pred_vec = np.zeros(embedding.shape[0])
    pred_vec[pred_idx] = 1

    y_true.append(true_vec)
    y_pred.append(pred_vec)

y_true = np.array(y_true)
y_pred = np.array(y_pred)

# âš™ï¸ Multi-label metrics
prec = precision_score(y_true, y_pred, average="micro", zero_division=0)
rec = recall_score(y_true, y_pred, average="micro", zero_division=0)
f1 = f1_score(y_true, y_pred, average="micro", zero_division=0)

# =========================================================
# ğŸ“ˆ IN Káº¾T QUáº¢
# =========================================================
print("\nğŸ¯ Evaluation Results (multi-label setting):")
print(f"Precision: {prec:.4f}")
print(f"Recall:    {rec:.4f}")
print(f"F1-score:  {f1:.4f}")

# =========================================================
# ğŸ” IN RA Dá»° ÄOÃN MÃƒ Bá»†NH CHO VÃ€I Bá»†NH NHÃ‚N MáºªU
# =========================================================
print("\nğŸ“‹ VÃ­ dá»¥ dá»± Ä‘oÃ¡n bá»‡nh tiáº¿p theo:")

for i, seq in enumerate(seqs[:5]):  # in 5 bá»‡nh nhÃ¢n Ä‘áº§u tiÃªn
    topk_pred = predict_topk(seq, k=5)
    last_visit = seq[-1] if len(seq) > 0 else []
    print(f"\nğŸ©º Bá»‡nh nhÃ¢n {i+1}:")
    print(f"  ğŸ”¹ MÃ£ bá»‡nh láº§n khÃ¡m gáº§n nháº¥t: {last_visit[:10]}{'...' if len(last_visit) > 10 else ''}")
    print(f"  ğŸ”® Dá»± Ä‘oÃ¡n top-5 mÃ£ bá»‡nh láº§n khÃ¡m tiáº¿p theo: {list(topk_pred)}")

print("\nâœ… ÄÃ¡nh giÃ¡ hoÃ n táº¥t! Model GRAM (fine-tuned) Ä‘Ã£ Ä‘Æ°á»£c kiá»ƒm tra trÃªn dá»¯ liá»‡u hybrid.")
